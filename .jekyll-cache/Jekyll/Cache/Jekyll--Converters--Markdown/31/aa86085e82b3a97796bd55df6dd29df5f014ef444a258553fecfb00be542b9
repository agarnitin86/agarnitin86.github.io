I"e<h3 id="objective">Objective</h3>

<p>This blog is inspired from the <a href="http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/">wildml blog</a> on text classification using convolution neural networks. This blog is based on the tensorflow code given in wildml blog. Here, in this blog i have taken two senetences as example and tried to explain what happens to the input data at each layer of the CNN. For each layer of the network it explains input for the layer, processing done and the output of each layer along with the shape of input and output data.<br />
This blog does not explains the basic working of CNN. It assumes that the reader has some understanding of CNNâ€™s</p>

<p><a href="https://github.com/dennybritz/cnn-text-classification-tf/blob/master/text_cnn.py">Github link to the code</a> being explained.</p>

<p>I will try to explain the network in the same order as it is in code.</p>

<ol>
  <li>Data processing</li>
  <li>Embedding Layer</li>
  <li>Convolution Layer</li>
  <li>Pooling Layer</li>
  <li>Dropout Layer</li>
  <li>Output Layer</li>
</ol>

<p>I Will be using following two sentences as input for our classification task:</p>

<p><strong>Sentence 1</strong> : The camera quality is very good<br />
<strong>Sentence 2</strong> : The battery life is good</p>

<p>Here we have two sentences of length 6 and 5 respectively.<br />
We also assume that their are two classes for our classification model, Positive and Negative.</p>

<h3 id="data-preprocessing-and-building-the-vocabulary">Data preprocessing and building the vocabulary</h3>

<p>Since the sentences are of different length, we pad our sentences with special <code class="language-plaintext highlighter-rouge">&lt;PAD&gt;</code> token to make the lengths of the two sentences equal.</p>

<p>So now we have our sentences modified as :<br />
<strong>Sentence 1</strong> : the camera quality is very good<br />
<strong>Sentence 2</strong> : the battery life is good <code class="language-plaintext highlighter-rouge">&lt;PAD&gt;</code>.<br />
Now, both the sentences are of same length. We proceed to build the vocabulary index.<br />
<strong>Vocabulary index</strong> is a mapping of integer to each unique word in the corpus.<br />
In our case, size of vocabulary index will be 9, since there are 9 unique tokens. Vocabulary is as follows
<img src="/images/vocabulary.png" alt="Drawing" style="width: 500px;" /></p>

<p>Corresponding code from the blog</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">vocab_processor</span> <span class="o">=</span> <span class="n">learn</span><span class="p">.</span><span class="n">preprocessing</span><span class="p">.</span><span class="n">VocabularyProcessor</span><span class="p">(</span><span class="n">max_document_length</span><span class="p">)</span></code></pre></figure>

<p>In tensorflow, tensorflow.contrib.learn.preprocessing.VocabularyProcessor is used for building the vocabulary.<br />
Use <a href="http://stackoverflow.com/questions/40661684/tensorflow-vocabularyprocessor">this link</a> to see how to extract vocabulary from the vocab_processor object.</p>

<p>Next, each sentence is converted into vector of integers.<br />
<strong>Sentence 1</strong> : [1, 2, 3, 4, 5, 6]<br />
<strong>Sentence 2</strong> : [1, 7, 8, 4, 6, 0]</p>

<h3 id="embedding-layer">Embedding Layer</h3>

<h4 id="configurable-parameters-for-embedding-layer">Configurable parameters for embedding layer</h4>

<ul>
  <li><strong>batch_size</strong> = 2 (Since we have only two sentences here)</li>
  <li><strong>sequence length</strong> = 6 (Max length of the senteces)</li>
  <li><strong>num_classes</strong>       = 2 (Number of output classes. Positive and negative in our case)</li>
  <li><strong>vocabulary size (V)</strong> = 9</li>
</ul>

<h4 id="trainable-parameters-for-embedding-layer">Trainable parameters for embedding layer</h4>

<ul>
  <li><strong>Embedding vector size (E)</strong> = 128 (Size of the embedding vector)</li>
  <li><strong>Embedding matrix (W) of shape</strong> = [V * E] = [9 * 128]</li>
</ul>

<h4 id="input">Input</h4>
<ul>
  <li><strong>shape of input (input_x)</strong> = [batch_size, sequence_length] = [2, 6]</li>
  <li><strong>shape of input (input_y)</strong> = [batch_size, num_classes] = [2, 2]<br />
Here, input_y are the output labels of input sentences encoded using one-hot encoding. Assuming both the sentences are positive (which will not be the actual case. There will also be negative sentences.)<br />
input_y = [ [1, 0], [1,0] ]</li>
</ul>

<h4 id="working-of-embedding-layer">Working of embedding layer</h4>

<p>As per the code in the <a href="http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/">wildml blog</a>:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="bp">self</span><span class="p">.</span><span class="n">input_x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s">"input_x"</span><span class="p">)</span></code></pre></figure>

<p>Input to the embedding layer is a tuple whose length is equal to the batch size, i.e, number of sentences in a batch.<br />
Each element of the tuple is an array of numbers, representing sentence in the form of indexes into vocabulary.<br />
For example : <br />
<img src="/images/SentenceRepresentation.png" alt="Drawing" style="width: 500px;" /></p>

<h4 id="embedding-lookup">Embedding Lookup</h4>
<p>Statement from the <a href="http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/">wildml blog</a></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="bp">self</span><span class="p">.</span><span class="n">embedded_chars</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">input_x</span><span class="p">)</span></code></pre></figure>

<p>This statement takes as input, input_x from the previous step.<br />
For each sentence, and for each word, it looks up (indexes) the embedding matrix (which is 9 * 128 in our case) (w) and returns the corresponding embedding vector for each word of each sentence.<br />
When i printed the variable <code class="language-plaintext highlighter-rouge">embedded_chars</code>, it is actually a list structured as follows :</p>

<ul>
  <li>embedded_chars is a list of size 1,</li>
  <li>its 0th element is a list of size batch_size, i.e, number of sentences, (2 for this ex)</li>
  <li>each element of this list is a list of size sequence_length, (6 for this ex)</li>
  <li>and, each element of this list is a list of size embedding vector (128 for this ex.)</li>
</ul>

<p>Here, the shape of tensor is <code class="language-plaintext highlighter-rouge">[batch_size, sequence_length, embedding_vector_length]</code>, i.e, <code class="language-plaintext highlighter-rouge">[2 * 6 * 128]</code>.</p>

<p>Each element of the word vector is a real value. In the next satement of the blog, i.e,</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="bp">self</span><span class="p">.</span><span class="n">embedded_chars_expanded</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">embedded_chars</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span></code></pre></figure>

<p>tensor is reshaped to <code class="language-plaintext highlighter-rouge">[batch_size, sequence_length, embedding_vector_length, 1]</code>,<br />
i.e, <code class="language-plaintext highlighter-rouge">[2 * 6 * 128 * 1]</code>. So that, each element of the word vector is itself a list of size 1, instead of a real number.<br />
Both the above statements can be easily understood from the following figure, where out = embedded_chars<br />
<img src="/images/SentenceRepresentationWordVector.png" alt="Drawing" style="width: 500px;" /><br />
This completes the explanation of embedding layer</p>

<h4 id="output-of-embedding-layer-">Output of embedding layer :</h4>

<ul>
  <li>Tensor of shape : <code class="language-plaintext highlighter-rouge">[batch_size, sequence_length, embedding_vector_length, 1]</code>, i.e, <code class="language-plaintext highlighter-rouge">[2 * 6 * 128 * 1]</code>.
Next layer in the model is the convolution layer.</li>
</ul>

<h3 id="convolution-layer">Convolution Layer</h3>

<h4 id="configurable-parameters-of-convolution-layer">Configurable parameters of convolution layer</h4>

<ul>
  <li><strong>filter_sizes</strong> : 3, 4, 5</li>
  <li><strong>num_filters</strong>: 128</li>
  <li><strong>Stride length</strong> : [1 * 1 * 1 * 1]</li>
  <li><strong>Padding</strong> : VALID<br />
As oppossed to 2D filters in images, here in text classification we use 1D filters. We will be using filters of sizes 3,4,5. First we will go through the process of a single filter. Same will work for the other two sizes. Later we will see, how to merge the output from all the three filter sizes.</li>
</ul>

<h4 id="trainable-parameters-of-convolution-layer">Trainable parameters of convolution layer</h4>
<ul>
  <li><strong>Weight matrix (W)</strong> : its shape is same as shape of filter.(Discussed next)</li>
  <li><strong>Bias(b)</strong> : = [0.1, 0.1, 0.1â€¦â€¦..0.1] Since there are 128 filters, there will be 128 bias values.</li>
</ul>

<h4 id="input-1">Input</h4>
<ul>
  <li>Output of the expanded embedding lookup step. Its shape is<br />
<code class="language-plaintext highlighter-rouge">[batch_size, sequence_length, embedding_vector_length, 1]</code>, i.e, <code class="language-plaintext highlighter-rouge">[2 * 6 * 128 * 1]</code></li>
</ul>

<p><strong>Now, what is the shape of filter ?</strong>
Lets take filter of size, <code class="language-plaintext highlighter-rouge">filter_size = 3</code>. In this case, shape of the filter is <code class="language-plaintext highlighter-rouge">[filter_height, fiter_width]</code> or <code class="language-plaintext highlighter-rouge">[filter_size, embedding_vector_length]</code> or <code class="language-plaintext highlighter-rouge">[3 * 128]</code>. This means that the filter sees 3 words (or embedding vectors) at  a time, and based on the stride keeps seeing the 3 word vectors.<br />
We have only one input channel, therefore, num_input_channels = 1<br />
Number of output channels or Number of filters is 128.
Therefore, shape of the filter tensor becomes : <code class="language-plaintext highlighter-rouge">[filter_size, embedding_vector_len, num_input_channels, num_filters] = [ 3 * 128 * 1 * 128]</code>
The following figure shows the mapping between input matrix and filter of size 3 : 
<img src="/images/CNN_Mapping_1.png" alt="Drawing" style="width: 500px;" /><br />
Here, the input only represents one sentence NOT both.<br />
I will explain how to apply convolution filter on the input in the next step, but, before that let us see how to compute the output shape for this filter of size 3.</p>

<p><strong>Now, what is the shape of output filter ?</strong><br />
For 1D case, as in text,<br />
<code class="language-plaintext highlighter-rouge">out_rows = (W1- F + 2 * P) / S + 1</code><br />
where,<br />
W1 = sequence_length (Number of input words) = 6 (in our case)<br />
F = height of filter or filter size = 3 (in our case)<br />
P = padding = 0 (in our case)<br />
Stride = 1 (in our case)</p>

<p>Therefore,<br />
<code class="language-plaintext highlighter-rouge">out_rows = (6 - 3 + 2 * 0) / 1 + 1 = 4</code><br />
Since the filter moves only in 1D, shape of output = 4 * 1, for a single sentence with a fiter_size = 3 and for one output channel.<br />
Now, since we have batch of sentences and num_filters = 128, we get 4 * 1 outputs for each combination. Therefore, shape of output tensor for fiter_size (3) is<br />
<code class="language-plaintext highlighter-rouge">[batch_size * 4 * 1 * num_filters] = [2 * 4 * 1 * 128]</code></p>

<p>Similarly, we can compute the output shapes for filters of size 4 and 5 as follows : <br />
<strong>For  filter_size (4)</strong> <code class="language-plaintext highlighter-rouge">(6 - 4 + 2 * 0) / 1 + 1 = 3</code> or <code class="language-plaintext highlighter-rouge">[2 * 3 * 1 * 128]</code><br />
<strong>For  filter_size (5)</strong> <code class="language-plaintext highlighter-rouge">(6 - 5 + 2 * 0) / 1 + 1 = 2</code> or <code class="language-plaintext highlighter-rouge">[2 * 2 * 1 * 128]</code><br />
Now let us see a simple calculation showing how filter is applied to input and what is the role of weight matrix and bias.<br />
Corresponding code statement:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">conv</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">conv2d</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">embedded_chars_expanded</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span>
                    <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                    <span class="n">padding</span><span class="o">=</span><span class="s">"VALID"</span><span class="p">,</span>
                    <span class="n">name</span><span class="o">=</span><span class="s">"conv"</span><span class="p">)</span></code></pre></figure>

<p><img src="/images/CNN_Mapping_WithCalculation.png" alt="Drawing" style="width: 500px;" /><br />
From the above figure, we get the result of applying fiter to patch of size 3 * 128, which is 5.76.<br />
In the case of tensorflow conv2d function, the conv2d function only performs elementwise multiplication of input patch and filter. The bias needs to be added separately.<br />
This is done in the next line of the code where nonlinearity is being applied along with bias addition.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">h</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">relu</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">bias_add</span><span class="p">(</span><span class="n">conv</span><span class="p">,</span> <span class="n">b</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s">"relu"</span><span class="p">)</span></code></pre></figure>

<p>Here, bias is being added to the output of conv layer for each patch-filter convolution. So, for the current patch we get 5.76 + 0.1 = 5.86.
On this output, relu is applied to, i.e, <code class="language-plaintext highlighter-rouge">max(0, x) = max(0, 5.86)  = 5.86</code>
So, we get h = 5.86 for the current patch.
The figure below describes the process for all the filters i.e, num_filters = 128.<br />
<img src="/images/FlowdiagCNN.png" alt="Drawing" style="width: 800px;" /><br />
The figure above shows the output, for, when 128 filters of size 3 are applied on  a single sentence. When applied to batch, shape becomes [batch_size * 4 * 1 * 128] = [2 * 4 * 1 * 128]</p>

<h3 id="pooling-layer">Pooling Layer</h3>

<h4 id="configurable-parameters-of-pooling-layer">Configurable parameters of pooling layer</h4>

<ul>
  <li><strong>ksize</strong> : shape of the pool operator <code class="language-plaintext highlighter-rouge">[1 * 4 * 1 * 128]</code></li>
  <li><strong>strides</strong> : same as conv2d <code class="language-plaintext highlighter-rouge">[1 * 1 * 1 * 1]</code></li>
</ul>

<p>Their are no training parameters for this layer. As only max operation is performed.<br />
Corresponding code statement:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">pooled</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">max_pool</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">ksize</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">sequence_length</span> <span class="o">-</span> <span class="n">filter_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                    <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                    <span class="n">padding</span><span class="o">=</span><span class="s">'VALID'</span><span class="p">,</span>
                    <span class="n">name</span><span class="o">=</span><span class="s">"pool"</span><span class="p">)</span></code></pre></figure>

<h4 id="input-2">Input</h4>
<p>Output of the convolution layer, whose shape is <code class="language-plaintext highlighter-rouge">[batch_size * 4 * 1 * num_filters ] = [2 * 4 * 1 * 128]</code>. Here, we are using the output from the filter of size, filter_size = 3<br />
In the max pooling layer we perform max operation on the output of each filter over the sentence, i.e, max operation on the <code class="language-plaintext highlighter-rouge">4 * 1</code> output of each filter.
The max  can be selected from all the 4 values, or we can define a different ksize. <br />
Here, we are using <code class="language-plaintext highlighter-rouge">ksize = [1 * (4 * 1) * 128]</code>, which means select the max out of all the four values. Since the selection is done from all the values, we get a single value as output for each of the 128 filters. This is demonstrated in the figure below :<br />
<img src="/images/PoolingLayer_1.png" alt="Drawing" style="width: 800px;" /></p>

<p>Therefore, we have max pooling output shape = [1 * 1 * 128] (128 - for each filter)</p>

<p>Now, suppose we change the <code class="language-plaintext highlighter-rouge">ksize = [1 * 2 * 1 * 128]</code>, and <code class="language-plaintext highlighter-rouge">stride = [1 * 1 * 1 * 1]</code>, we get output of <code class="language-plaintext highlighter-rouge">shape [3 * 1]</code> for each of 128 filters as shown below:</p>

<p><img src="/images/PoolingLayer_2.png" alt="Drawing" style="width: 800px;" /></p>

<p>In our text classification problem filter moves only in one direction, therefore, size = 3 * 1. It it had moved along horizontal direction also (as in images), the shape of output would have been (3 * a) where a &gt; 1</p>

<h4 id="merging-the-output-of-max-pooling-layer-for-each-filter-size3-4-5">Merging the output of max pooling layer for each filter size(3, 4, 5).</h4>
<p>Corresponding code statement:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="bp">self</span><span class="p">.</span><span class="n">h_pool</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">concat</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">pooled_outputs</span><span class="p">)</span></code></pre></figure>

<p>Now, for the current example we have 3 different filter size (3,4,5). For each filter size we get a tensor of shape [1 * 1 * 128]. These tensors are concatenated. So, we have 3 tensors of shape [1 * 1 * 128] to get a tensor of shape [3 * 1 * 1 * 128]. Since, the same is done for each sentence in the batch, shape of the tensor becomes <code class="language-plaintext highlighter-rouge">[batch_size * 3 * 1 * 1 * 128] = [2 * 3 * 1 * 1 * 128]</code> as shown below</p>

<p><img src="/images/ConcatenateReshape.png" alt="Drawing" style="width: 800px;" /></p>

<p>Next, in the code,</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"> <span class="bp">self</span><span class="p">.</span><span class="n">h_pool_flat</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">h_pool</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_filters_total</span><span class="p">])</span></code></pre></figure>

<p>a reshape is performed to get a tensor of shape <code class="language-plaintext highlighter-rouge">[batch_size, (3* 128)] = [batch_size , 384]  = [2 * 384]</code>. This means, now for each sentence we have a fiter output in a row as shown above.</p>

<h3 id="dropout-layer">Dropout Layer</h3>
<p>Corresponding code statement</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="bp">self</span><span class="p">.</span><span class="n">h_drop</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">h_pool_flat</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout_keep_prob</span><span class="p">)</span></code></pre></figure>

<p>In this layer simply dropout is applied. Input and output shapes remain the same.</p>

<ul>
  <li>Input shape    : [batch_size * 384] = [2 * 384]</li>
  <li>Output shape : [batch_size * 384] = [2 * 384]</li>
</ul>

<h3 id="output-layer">Output Layer</h3>
<p>Corresponding code statement</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="bp">self</span><span class="p">.</span><span class="n">scores</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">xw_plus_b</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">h_drop</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"scores"</span><span class="p">)</span></code></pre></figure>

<h4 id="configurable-parameters-of-output-layer">Configurable parameters of output layer</h4>

<ul>
  <li><strong>Weight matrix (W)</strong> of shape [ total_num_filters * num_classes]<br />
where, <code class="language-plaintext highlighter-rouge">total_num_filters = length([3, 4, 5]) * num_filters = 3 * 128 = 384</code>,<br />
          <code class="language-plaintext highlighter-rouge">num_classes = 2</code>,
Therefore, shape of W = [384 * 2]</li>
  <li><strong>Bias (b)</strong> of shape [num_classes] = [2] or<br />
b = [0.1, 0.1]</li>
</ul>

<h4 id="input-3">Input</h4>
<p>Output of the previous dropout layer with shape <code class="language-plaintext highlighter-rouge">[2 * 384]</code>. So, the size of each input vector is 384.</p>

<h4 id="working">Working</h4>
<p>For each input vector (x) from the previous layer, <code class="language-plaintext highlighter-rouge">xW + b</code> is calculated,<br />
where x is a row vector of <code class="language-plaintext highlighter-rouge">[384]</code> elements, W is <code class="language-plaintext highlighter-rouge">[384 * 2]</code>.<br />
So, for each sentence we get a vector of length 2 (num_classes),<br />
and, for the batch of size batch_size, output shape is <code class="language-plaintext highlighter-rouge">[batch_size * num_classes] = [2 * 2]</code> as shown below</p>

<p><img src="/images/OutputLayer.png" alt="Drawing" style="width: 400px;" /></p>

<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = '//agarnitin86-github-io.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

:ET
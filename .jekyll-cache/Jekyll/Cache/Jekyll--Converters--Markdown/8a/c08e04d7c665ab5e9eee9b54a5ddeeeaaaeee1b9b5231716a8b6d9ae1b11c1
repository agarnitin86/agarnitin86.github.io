I"l-<h2 id="this-resource-contains-help-functionssteps-for-following-tasks">This resource contains help functions/steps for following tasks:</h2>

<ol>
  <li>Using ColumnTransformer <a href="#col-trans">here</a></li>
  <li>Search for available GPUs</li>
  <li>Steps to handle nan in loss during training</li>
  <li>Steps to increase gpu utilization and speed of processing</li>
  <li>Commands to monitor gpu usage</li>
  <li>Commands to run tensorboard</li>
  <li>Command to create tar file</li>
  <li>Command to compute per user memory usage</li>
  <li>Shell script to compress all files in a directory and delete the originial file from the directory. This script will create separate tar file for each file in the directory</li>
  <li>Setting up tensorflow environment variables</li>
  <li>Setting up LD_LIBRARY_PATH variable for tensorflow</li>
  <li>Some useful steps to setup server for Deep Learning</li>
  <li>Shell command to check folder wise disk usage</li>
  <li>Filezilla: Error: Disconnected: No supported authentication methods available (server sent: publickey)</li>
</ol>

<hr />

<h2 id="links">Links</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: right">S.No.</th>
      <th style="text-align: right">Category</th>
      <th>Task</th>
      <th style="text-align: center">Link</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">1.</td>
      <td style="text-align: right">Tensorflow</td>
      <td>Tensorflow version compatibility chart</td>
      <td style="text-align: center">https://www.tensorflow.org/install/source</td>
    </tr>
    <tr>
      <td style="text-align: right">2.</td>
      <td style="text-align: right">Cuda, Tensorflow</td>
      <td>Steps needed to install cuda &amp; runtime libraries</td>
      <td style="text-align: center">https://www.tensorflow.org/install/gpu#ubuntu_1604_cuda_10</td>
    </tr>
  </tbody>
</table>

<hr />

<p><strong>Using ColumnTransformer</strong>
This code demonstrates how to use ColumnTransformer</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">make_column_transformer</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s">'region'</span><span class="p">:[</span><span class="s">'a'</span><span class="p">,</span><span class="s">'a'</span><span class="p">,</span><span class="s">'b'</span><span class="p">,</span><span class="s">'c'</span><span class="p">],</span> <span class="s">'country'</span><span class="p">:[</span><span class="s">'c1'</span><span class="p">,</span> <span class="s">'c1'</span><span class="p">,</span> <span class="s">'c2'</span><span class="p">,</span> <span class="s">'c3'</span><span class="p">]})</span>
<span class="n">categorical_features</span> <span class="o">=</span> <span class="p">[</span><span class="s">'region'</span><span class="p">,</span><span class="s">'country'</span><span class="p">]</span>
<span class="n">preprocessor</span> <span class="o">=</span> <span class="n">make_column_transformer</span><span class="p">((</span><span class="n">OneHotEncoder</span><span class="p">(),</span> <span class="n">categorical_features</span><span class="p">))</span>
<span class="n">df_new</span> <span class="o">=</span> <span class="n">preprocessor</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div></div>
<hr />

<p><strong>Search for available GPUs</strong>
How to get list of GPUs visible to tensorflow/keras</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from keras import backend
backend.tensorflow_backend._get_available_gpus()

import keras
import tensorflow as tf
config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) 
sess = tf.Session(config=config) 
keras.backend.set_session(sess)

from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())

import tensorflow as tf
tf.test.is_gpu_available() tells if the gpu is available
tf.test.gpu_device_name returns the name of the gpu device

with tf.Session() as sess:
  devices = sess.list_devices()
</code></pre></div></div>

<hr />

<p><strong>Steps to handle nan in loss during training:</strong></p>

<ol>
  <li>Normalize your outputs by quantile normalizing or z scoring. To be rigorous, compute this transformation on the training data, not on the entire dataset.</li>
  <li>Add regularization, either by increasing the dropout rate or adding L1 and L2 penalties to the weights.</li>
  <li>reduce the size of your network.</li>
  <li>Increase the batch size from 32 to 128. 128 is fairly standard and could potentially increase the stability of the optimization.</li>
  <li>In Keras you can use clipnorm=1 (see https://keras.io/optimizers/) to simply clip all gradients with a norm above 1.</li>
  <li>It turns out, one of the images that I was handing to my CNN (and doing mean normalization on) was nothing but 0’s. I wasn’t checking for this case when I subtracted the mean and normalized by the std deviation and thus I ended up with an exemplar matrix which was nothing but nan’s.</li>
  <li>The first thing you can try is changing your activation to LeakyReLU instead of using Relu or Tanh.</li>
  <li>Column in my data set had all the same numerical value, making it effectively a worthless addition to the DNN.</li>
</ol>

<hr />

<p><strong>Steps to increase gpu utilization and speed of processing</strong></p>
<ol>
  <li>Clear Keras session using K.clear_session</li>
  <li>Use fit_gen instead of fit if data is huge</li>
  <li>Use early stopping</li>
  <li>Use multiple workers in fit/fit_gen. (This has no been checked)</li>
  <li>Try increasing validation_freq</li>
  <li>If using LSTM try using cuDNNLSTM instead of LSTM</li>
  <li>If using LSTM try using unroll = True option</li>
</ol>

<hr />
<p><strong>Commands to monitor gpu usage</strong>
$ nvidia-smi -l 1 
$ watch -n 0.5 nvidia-smi</p>

<p><strong>Commands to run tensorboard</strong> 
tensorboard –logdir=./iteration_7/model/logs/ –port=8097 –host=127.0.0.1</p>

<p><strong>Command to create tar file</strong> 
tar -czvf moscow.tar.gz ./store_log_calendar_Moscow.csv</p>

<p><strong>Command to compute per user memory usage</strong> 
ps aux | awk ‘{arr[$1]+=$4}; END {for (i in arr) {print i,arr[i]}}’ | sort -k2</p>

<p><strong>Shell script to compress all files in a directory and delete the originial file from the directory. This script will create separate tar file for each file in the directory</strong> 
for i in * ; do tar cvzf $i.tar.gz $i; rm -rf $i; done</p>

<hr />

<h2 id="setting-up-tensorflow-environment">Setting up tensorflow environment</h2>

<p><strong>Environment variables for tensorflow-gpu:</strong>
TF_FORCE_GPU_ALLOW_GROWTH = True</p>

<p><strong>Configuration parameters to be set in code</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>config.gpu_options.allow_growth = True
config.gpu_options.visible_device_list = which_gpu
config.gpu_options.per_process_gpu_memory_fraction = 0.4
</code></pre></div></div>
<p><strong>Code to dynamically grow GPU memory (instead of allocating everything at once)</strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import tensorflow as tf 
from keras.backend.tensorflow_backend import set_session
config = tf.ConfigProto()
config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU
sess = tf.Session(config=config)
set_session(sess) 
</code></pre></div></div>
<hr />

<p><strong>Some useful steps to setup server for Deep Learning</strong></p>

<p><strong>Download the anaconda installer</strong>
$ wget https://repo.anaconda.com/archive/Anaconda3-2018.12-Linux-x86_64.sh
or
$ wget https://repo.anaconda.com/archive/Anaconda3-2019.03-Linux-x86_64.sh</p>

<p><strong>Run the installer</strong>
$ bash Anaconda3-2019.03-Linux-x86_64.sh
$ source .bashrc</p>

<p><strong>Upgrade conda (Might not be required, check the instructions)</strong>
conda upgrade conda
or
conda upgrade –all</p>

<p><strong>Create new virtual environment in conda</strong>
$ conda create -n venv_rb python=3.5
$ conda activate venv_rb</p>

<p><strong>Some useful commands to check the environment</strong>
$ conda info
$ conda list
$ which pip</p>

<p><strong>Installing some useful packages</strong>
$ pip install –upgrade tensorflow-gpu
$ pip install keras
$ conda install pandas
$ pip install matplotlib
$ pip install -U scikit-learn
$ pip install jupyter
$ pip install pandas-profiling</p>

<p><strong>Setting up LD_LIBRARY_PATH variable for tensorflow</strong>
export LD_LIBRARY_PATH=/usr/local/cuda-10.0/lib64</p>

<p><strong>Additional steps needed to install cuda &amp; runtime libraries (Select based on ubuntu &amp; tensorflow-gpu versions)</strong>
https://www.tensorflow.org/install/gpu#ubuntu_1604_cuda_10</p>

<p><strong>Tensorflow version compatibility chart</strong>
https://www.tensorflow.org/install/source</p>

<hr />

<p><strong>Shell command to check folder wise disk usage</strong>
$ du -h –max-depth=1 /data/rb/users/|sort -h</p>

<hr />

<p><strong>Filezilla error while connecting</strong></p>

<p>Error:	Disconnected: No supported authentication methods available (server sent: publickey)
Error:	Could not connect to server</p>

<p><strong>Solution</strong>
If you have private key file (.ppk file):
In Filezilla,
Go to Edit » Settings » SFTP » Add Key File
Upload your private key file and try to re-connect.</p>

<hr />

<p><strong>How to add equations to you Readme file in github</strong></p>

<p><strong>Solution</strong>
https://stackoverflow.com/questions/35498525/latex-rendering-in-readme-md-on-github
Take your latex equation and go to http://www.codecogs.com/latex/eqneditor.php, at the bottom of the area where your equation appears displayed there is a tiny dropdown menu, pick URL encoded and then paste that in your github markdown</p>

<hr />

<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = '//agarnitin86-github-io.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
:ET